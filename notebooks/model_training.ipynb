{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54233b-520e-42ef-ad9a-28c60d8d046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d9d63-f456-4391-b9eb-b329c5e28e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global configuration\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a367e4-6144-4147-8075-b7ea57cd3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning function\n",
    "def clean_text(s):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes tweet text.\n",
    "    - Converts to lowercase\n",
    "    - Removes URLs, mentions, hashtags, and special characters\n",
    "    - Keeps only alphabetic text\n",
    "    \"\"\"\n",
    "    import re\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', '', s)\n",
    "    s = re.sub(r'@\\w+', '', s)\n",
    "    s = re.sub(r'#', '', s)\n",
    "    s = re.sub(r'[^a-z\\s]', '', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264ae45-ac43-47ae-8de6-c43f2372552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading and preperation\n",
    "def load_and_prep(path):\n",
    "    \"\"\"\n",
    "    Loads and prepares dataset.\n",
    "    - Reads CSV file\n",
    "    - Creates 'label' column (1 = foul/offensive, 0 = proper)\n",
    "    - Applies text cleaning\n",
    "    - Returns a DataFrame with cleaned text and labels\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Map dataset columns to a unified label column\n",
    "    if 'class' in df.columns:\n",
    "        df['label'] = df['class'].map(lambda x: 1 if x in [0, 1] else 0)\n",
    "    elif {'hate_speech', 'offensive_language'}.issubset(df.columns):\n",
    "        df['label'] = df[['hate_speech', 'offensive_language']].max(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"No valid label column found\")\n",
    "\n",
    "    # Standardize text column name\n",
    "    df['text'] = df.get('text', df.get('tweet', df.iloc[:, 0])).astype(str)\n",
    "    df['clean_text'] = df['text'].apply(clean_text)\n",
    "    return df[['clean_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39db3d-afd2-4254-9cd0-4a7ff7164d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold selection\n",
    "def choose_threshold(model, X_val_vec, y_val, recall_target=0.8):\n",
    "    \"\"\"\n",
    "    Finds the best threshold for given recall target.\n",
    "    - Uses precision-recall curve\n",
    "    - Selects threshold that achieves target recall\n",
    "    - Clips threshold to 0.4–0.95 range for stability\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(X_val_vec)[:, 1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, probs)\n",
    "\n",
    "    thresholds_ext = list(thresholds) + [1.0]\n",
    "    candidates = []\n",
    "    for p, r, t in zip(precision, recall, thresholds_ext):\n",
    "        if r >= recall_target:\n",
    "            f1 = (2 * p * r) / (p + r + 1e-9)\n",
    "            candidates.append((t, p, r, f1))\n",
    "\n",
    "    if candidates:\n",
    "        best = max(candidates, key=lambda x: (x[1], x[3]))\n",
    "        thr = float(best[0])\n",
    "    else:\n",
    "        f1s = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "        idx = np.nanargmax(f1s)\n",
    "        thr = float(np.append(thresholds, 1.0)[idx])\n",
    "\n",
    "    thr = float(np.clip(thr, 0.4, 0.95))\n",
    "    return thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960c5d0-bfb2-424f-9d28-15021923b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training and saving\n",
    "def train_and_save_model(df, recall_target, outpath):\n",
    "    \"\"\"\n",
    "    Trains and saves a Logistic Regression classifier.\n",
    "    - Splits dataset into train/val/test\n",
    "    - Applies TF-IDF vectorization (1–2 n-grams)\n",
    "    - Uses GridSearchCV to tune 'C'\n",
    "    - Chooses best threshold based on recall target\n",
    "    - Saves trained model and vectorizer as a pickle file\n",
    "    \"\"\"\n",
    "    # Split data\n",
    "    X = df['clean_text']\n",
    "    y = df['label']\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_features=30000)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_val_vec = vectorizer.transform(X_val)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Handle class imbalance\n",
    "    weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight = {0: weights[0] * 0.7, 1: weights[1] * 0.7}\n",
    "\n",
    "    # Logistic Regression model\n",
    "    clf = LogisticRegression(\n",
    "        solver='saga',\n",
    "        max_iter=2000,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "\n",
    "    # Grid search for best regularization parameter\n",
    "    gs = GridSearchCV(clf, {'C': [0.1, 1.0, 5.0]}, cv=3, scoring='f1', n_jobs=-1)\n",
    "    gs.fit(X_train_vec, y_train)\n",
    "    best = gs.best_estimator_\n",
    "\n",
    "    # Choose optimal threshold\n",
    "    threshold = choose_threshold(best, X_val_vec, y_val, recall_target)\n",
    "    probs_test = best.predict_proba(X_test_vec)[:, 1]\n",
    "    preds_test = (probs_test >= threshold).astype(int)\n",
    "\n",
    "    # Evaluation results\n",
    "    print(f\"\\n=== Model (Recall target={recall_target}) ===\")\n",
    "    print(classification_report(y_test, preds_test))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, probs_test))\n",
    "    print(\"PR AUC:\", average_precision_score(y_test, probs_test))\n",
    "    print(\"Chosen threshold:\", threshold)\n",
    "\n",
    "    # Save model\n",
    "    artifact = {'vectorizer': vectorizer, 'model': best, 'threshold': threshold}\n",
    "    os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "    with open(outpath, 'wb') as f:\n",
    "        pickle.dump(artifact, f)\n",
    "    print(\"✅ Saved:\", outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4ffe5-c367-4915-a6b8-a7c1630cd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main script excecution \n",
    "if __name__ == '__main__':\n",
    "    df = load_and_prep(\"data/labeled_data.csv\")\n",
    "\n",
    "    train_and_save_model(df, 0.85, \"model_artifacts/foul_detector_low.pkl\")\n",
    "    train_and_save_model(df, 0.9,  \"model_artifacts/foul_detector_medium.pkl\")\n",
    "    train_and_save_model(df, 0.95, \"model_artifacts/foul_detector_high.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
